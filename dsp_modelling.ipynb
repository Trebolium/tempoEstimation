{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'my_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import medfilt as medfilt\n",
    "from scipy import signal\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a csv file to a python list of rows\n",
    "def csvfile_to_list(fp):\n",
    "    f = open(fp)\n",
    "    reader = csv.reader(f)\n",
    "    _ = next(reader)\n",
    "    list_of_rows = [row for row in reader]\n",
    "    return list_of_rows\n",
    "\n",
    "\n",
    "# returns a list of filepaths collected from a parent directory and all subdirectories\n",
    "def recursive_file_retrieval(parent_path, ignore_hidden_dirs=False, return_parent=True):\n",
    "    \n",
    "    file_path_list = []\n",
    "    dir_list = []\n",
    "    parent_paths = [parent_path]\n",
    "\n",
    "    more_subdirs = True\n",
    "    while more_subdirs == True:\n",
    "        subdir_paths = []\n",
    "        for i, parent_path in enumerate(parent_paths):\n",
    "            # print(parent_path)\n",
    "            if ignore_hidden_dirs:\n",
    "                if os.path.basename(parent_path).startswith('.'):\n",
    "                    continue\n",
    "\n",
    "            dir_list.append(parent_path)\n",
    "            r,dirs,files = next(os.walk(parent_path, topdown=True, onerror=None, followlinks=False)) \n",
    "            for f in files:\n",
    "                file_path_list.append(os.path.join(r,f))\n",
    "\n",
    "            # if there are more subdirectories\n",
    "            if len(dirs) != 0:\n",
    "                for d in dirs:\n",
    "                    subdir_paths.append(os.path.join(r,d))\n",
    "\n",
    "            # if we've finished going through subdirectories (each parent_path), stop that loop\n",
    "            if i == len(parent_paths)-1:\n",
    "                # if loop about to finish, change parent_paths content and restart loop\n",
    "                if len(subdir_paths) != 0:\n",
    "                    parent_paths = subdir_paths\n",
    "                else:\n",
    "                    more_subdirs = False\n",
    "    \n",
    "    if not return_parent: dir_list = dir_list[1:]\n",
    "\n",
    "    return dir_list, file_path_list\n",
    "\n",
    "\n",
    "def plot_ts(ts, hop_duration=0.016):\n",
    "    time = np.arange(len(ts))*hop_duration\n",
    "\n",
    "    # Plot the time series\n",
    "    plt.plot(time, ts, label='Time Series')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Time Series Example')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def normalise(arr):\n",
    "    mx = arr.max() # removed axis=1\n",
    "    for i in range(mx.shape[0]):\n",
    "        if mx[i] > 0:\n",
    "            arr[i,:] /= mx[i]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def tau_to_tempo(tau, hop=0.016, output='bpm'):\n",
    "    period = tau * hop\n",
    "    if output == 'bpm':\n",
    "        return period_to_bpm(period)\n",
    "    else:\n",
    "        return period\n",
    "\n",
    "\n",
    "def period_to_bpm(period):\n",
    "    return 60/period\n",
    "\n",
    "\n",
    "def beats_from_beatfile(fp):\n",
    "    csv_rows = csvfile_to_list(fp)\n",
    "    ts_beats = []\n",
    "    for r in csv_rows:\n",
    "        entry = r[0]\n",
    "        entries = entry.split('\\t')\n",
    "        timestamp, beat = float(entries[0]), int(entries[1])\n",
    "        ts_beats.append((timestamp, beat))\n",
    "    return ts_beats\n",
    "\n",
    "\n",
    "def temp_from_beatsfile(fp, output='bpm', summation='mean'):\n",
    "    ts_beats = beats_from_beatfile(fp)\n",
    "    timestamps = np.array([ts for ts, b in ts_beats])\n",
    "    if summation == 'mean':\n",
    "        mean_period = np.mean(np.diff(timestamps))\n",
    "    elif summation == 'median':\n",
    "        mean_period = np.median(np.diff(timestamps))\n",
    "    if output == 'bpm':\n",
    "        return round(period_to_bpm(mean_period))\n",
    "    elif output == 'period':\n",
    "        return mean_period\n",
    "    \n",
    "\n",
    "# get several onset arrays using several dsp approaches\n",
    "def get_onset_arrs(specs):\n",
    "   \n",
    "    # get rms values\n",
    "    rms_values = np.sqrt(np.mean(specs**2, axis=1))\n",
    "    dim = specs.shape[1]\n",
    "    # get high frequency content measure\n",
    "    hfc_muliplier = np.asarray(range(dim))+1\n",
    "    hfc = np.mean((specs * hfc_muliplier), axis=1)\n",
    "    # get spectral flux\n",
    "    delta_spectrogram = np.diff(specs, axis=0)\n",
    "    delta_spectrogram = np.concatenate((np.zeros((1,dim)), delta_spectrogram))\n",
    "    mask = delta_spectrogram > 0\n",
    "    delta_spec_up = delta_spectrogram * mask\n",
    "    spec_flux = np.sum(delta_spec_up, axis=1)\n",
    "\n",
    "    return rms_values, hfc, spec_flux\n",
    "    \n",
    "\n",
    "# Clean up onset arrays: Smoothen, normalise, denoise, peak-isolation\n",
    "def cleanup_onset_array(ts, mf_k=3, threshold=0.5, autocor_peak_dist=5):\n",
    "    med_ts = ts - medfilt(ts, mf_k)\n",
    "    med_grad_ts = np.gradient(med_ts)\n",
    "    stdise_med_grad_ts = (med_grad_ts - np.mean(med_grad_ts)) / np.std(med_grad_ts)\n",
    "    min_max_med_grad_ts = med_grad_ts / np.max(med_grad_ts)\n",
    "    normmed_med_grad_ts = stdise_med_grad_ts\n",
    "    thresholded_ts = normmed_med_grad_ts.copy()\n",
    "    thresholded_ts[thresholded_ts < threshold] = 0\n",
    "    onset_peak_indices, peak_value_dict = signal.find_peaks(thresholded_ts, height=0, distance=autocor_peak_dist)\n",
    "    peak_values = peak_value_dict['peak_heights']\n",
    "    trimmed_odf = np.zeros_like(thresholded_ts)\n",
    "    trimmed_odf[onset_peak_indices] = peak_values\n",
    "    return trimmed_odf\n",
    "\n",
    "\n",
    "# get tempo candidantes from onset array\n",
    "def get_tempo(onsets, tau_limits):\n",
    "    autocor = np.correlate(onsets, onsets, mode='full')[int(len(np.correlate(onsets, onsets, mode='full'))//2)+1:]\n",
    "    acf_peak_indices, acf_peak_value_dict = signal.find_peaks(autocor, height=np.max(autocor)/2, distance=5)\n",
    "    acf_peak_values = acf_peak_value_dict['peak_heights']\n",
    "    peaked_autocor = np.zeros_like(autocor)\n",
    "    peaked_autocor[acf_peak_indices] = acf_peak_values\n",
    "    realistic_autocor_cands = peaked_autocor[tau_limits[1]:tau_limits[0]]\n",
    "    best_tau_samples = np.argpartition(realistic_autocor_cands, -4)[-4:]\n",
    "    return [round(tau_to_tempo(t)) for t in best_tau_samples]\n",
    "\n",
    "\n",
    "def beatsfp_from_featsfp(feats_fp, beats_dir):\n",
    "    fn = os.path.basename(feats_fp)\n",
    "    genre, id = fn.split('.')[:2]\n",
    "    beats_basename = 'gtzan_' +genre +'_' + id +'.beats'\n",
    "    beats_fp = os.path.join(beats_dir, beats_basename)\n",
    "    return beats_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dir = '/Users/brendanoconnor/Desktop/career/tempoEstimationTask/stored_feats'\n",
    "beats_dir = '/Users/brendanoconnor/Downloads/MLExcerciseBrendan/data/GTZAN/beats'\n",
    "threshold = 0.5\n",
    "bpm_limits = [50, 250]\n",
    "mf_k=3\n",
    "ofd_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fft_size': 1024, 'fmax': 7600, 'fmin': 90, 'hop_size': 256, 'num_mels': 80, 'sr': 16000}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(feats_dir, \"feat_params.yaml\"), \"rb\") as handle:\n",
    "    feat_params = yaml.load(handle, Loader=yaml.FullLoader)\n",
    "\n",
    "print(feat_params)\n",
    "\n",
    "# onset detection function generators\n",
    "hop_duration = feat_params['hop_size'] / feat_params['sr']\n",
    "dim_size = feat_params['num_mels']\n",
    "tau_limits = [round(1 / (bpm / 60 * hop_duration)) for bpm in bpm_limits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect premade features and derive onsets from them in several ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fps = recursive_file_retrieval(feats_dir)\n",
    "filt_fps = [fp for fp in fps if not fp.startswith('.') and fp.endswith('npy')]\n",
    "\n",
    "fps_onsets = []\n",
    "feats_fp = '/Users/brendanoconnor/Desktop/career/tempoEstimationTask/stored_feats/pop/pop.00000.wav.npy'\n",
    "\n",
    "for feats_fp in filt_fps:\n",
    "    feats = np.load(feats_fp)\n",
    "    fps_onsets.append((feats_fp, get_onset_arrs(feats)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 [64, 69, 312, 144]\n",
      "94 [87, 938, 114, 163]\n",
      "122 [110, 83, 1250, 250]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fp_onset in fps_onsets:\n",
    "    fp, onsets = fp_onset[0], fp_onset[1]\n",
    "    onset_arr = onsets[ofd_idx]\n",
    "    cleanedup_onset_arr = cleanup_onset_array(onset_arr)\n",
    "    bpms = get_tempo(cleanedup_onset_arr, tau_limits)\n",
    "    beats_fp = beatsfp_from_featsfp(fp, beats_dir)\n",
    "    print(temp_from_beatsfile(beats_fp, summation='mean'), bpms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
